{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this variable will be used in `runner.train` and by default we disable FP16 mode\n",
    "is_fp16_used = False\n",
    "is_alchemy_used = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for augmentations\n",
    "# !pip install albumentations\n",
    "\n",
    "# # for pretrained models for PyTorch\n",
    "# !pip install pretrainedmodels\n",
    "\n",
    "\n",
    "# ################\n",
    "# # Catalyst itself\n",
    "# !pip install -U catalyst\n",
    "# # For specific version of catalyst, uncomment:\n",
    "# # ! pip install git+http://github.com/catalyst-team/catalyst.git@{master/commit_hash}\n",
    "# ################\n",
    "\n",
    "# # for TTA\n",
    "# # !pip install ttach\n",
    "\n",
    "# # for tensorboard\n",
    "# !pip install tensorflow\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# # for alchemy experiment logging integration, uncomment this 2 lines below\n",
    "# # !pip install -U alchemy\n",
    "# # is_alchemy_used = True\n",
    "\n",
    "# # if Your machine support Apex FP16, uncomment this 3 lines below\n",
    "# # !git clone https://github.com/NVIDIA/apex\n",
    "# # !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex\n",
    "# # is_fp16_used = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrate visualization library to colab\n",
    "import IPython\n",
    "\n",
    "def configure_plotly_browser_state():\n",
    "    display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))\n",
    "\n",
    "\n",
    "IPython.get_ipython().events.register('pre_run_cell', configure_plotly_browser_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/users/ziqbal5/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/users/ziqbal5/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/users/ziqbal5/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "alchemy not available, to install alchemy, run `pip install alchemy-catalyst`.\n",
      "/home/users/ziqbal5/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/home/users/ziqbal5/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:5879: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/home/users/ziqbal5/.keras/keras.json' mode='r' encoding='UTF-8'>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.4.0, catalyst: 20.04.1\n"
     ]
    }
   ],
   "source": [
    "#setting up GPUs\n",
    "from typing import Callable, List, Tuple \n",
    "\n",
    "import os\n",
    "import torch\n",
    "import catalyst\n",
    "\n",
    "from catalyst.dl import utils\n",
    "SEED = 42\n",
    "utils.set_global_seed(SEED)\n",
    "utils.prepare_cudnn(deterministic=True)\n",
    "print(f\"torch: {torch.__version__}, catalyst: {catalyst.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 828\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT= '/data/mialab/users/AA/Zafar/adni_smri/'\n",
    "ALL_IMAGES = list(Path(ROOT).glob(\"**/*.nii\"))\n",
    "ALL_IMAGES = list(filter(lambda x: not x.name.startswith(\".\"), ALL_IMAGES))\n",
    "print(\"Number of images:\", len(ALL_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check out the data\n",
    "from catalyst.utils import imread\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_examples(images: List[Tuple[str, np.ndarray]]):\n",
    "    _indexes = [(i, j) for i in range(2) for j in range(2)]\n",
    "    \n",
    "    f, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "    for (i, j), (title, img) in zip(_indexes, images):\n",
    "        ax[i, j].imshow(img)\n",
    "        ax[i, j].set_title(title)\n",
    "    f.tight_layout()\n",
    "\n",
    "def read_random_images(paths: List[Path]) -> List[Tuple[str, np.ndarray]]:\n",
    "    data = np.random.choice(paths, size=4)\n",
    "    result = []\n",
    "    for d in data:\n",
    "        title = f\"{d.parent.name}: {d.name}\"\n",
    "        _image = imread(d)\n",
    "        result.append((title, _image))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create dataset\n",
    "from catalyst.utils import (\n",
    "    create_dataset, create_dataframe, get_dataset_labeling, map_dataframe\n",
    ")\n",
    "\n",
    "dataset = create_dataset(dirs=f\"{ROOT}/*\", extension=\"*.nii\")\n",
    "df = create_dataframe(dataset, columns=[\"class\", \"filepath\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from catalyst.dl import utils\n",
    "from catalyst.data import ImageReader, ScalarReader, ReaderCompose\n",
    "\n",
    "num_classes = 4\n",
    "\n",
    "# ReaderCompose collects different Readers into one pipeline\n",
    "open_fn = ReaderCompose([\n",
    "    \n",
    "    # Reads images from the `rootpath` folder \n",
    "    # using the key `input_key =\" filepath \"` (here should be the filename)\n",
    "    # and writes it to the output dictionary by `output_key=\"features\"` key\n",
    "    ImageReader(\n",
    "        input_key=\"filepath\",\n",
    "        output_key=\"features\",\n",
    "        rootpath=ROOT\n",
    "    ),\n",
    "    \n",
    "    # Reads a number from our dataframe \n",
    "    # by the key `input_key =\" label \"` to np.long\n",
    "    # and writes it to the output dictionary by `output_key=\"targets\"` key\n",
    "    ScalarReader(\n",
    "        input_key=\"label\",\n",
    "        output_key=\"targets\",\n",
    "        default_value=-1,\n",
    "        dtype=np.int64\n",
    "    ),\n",
    "    \n",
    "    # Same as above, but with one encoding\n",
    "    ScalarReader(\n",
    "        input_key=\"label\",\n",
    "        output_key=\"targets_one_hot\",\n",
    "        default_value=-1,\n",
    "        dtype=np.int64, \n",
    "        one_hot_classes=num_classes\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FAQ</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>ADAS11</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>RAVLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/mialab/users/AA/Zafar/adni_smri/0001/SmN...</td>\n",
       "      <td>1</td>\n",
       "      <td>84.8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/mialab/users/AA/Zafar/adni_smri/0002/SmN...</td>\n",
       "      <td>1</td>\n",
       "      <td>76.3</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4.33</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/mialab/users/AA/Zafar/adni_smri/0003/SmN...</td>\n",
       "      <td>1</td>\n",
       "      <td>79.3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/mialab/users/AA/Zafar/adni_smri/0004/SmN...</td>\n",
       "      <td>3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.33</td>\n",
       "      <td>30.33</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/mialab/users/AA/Zafar/adni_smri/0005/SmN...</td>\n",
       "      <td>1</td>\n",
       "      <td>89.6</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>6.67</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label   age  MMSE  FAQ  \\\n",
       "0  /data/mialab/users/AA/Zafar/adni_smri/0001/SmN...      1  84.8    28    0   \n",
       "1  /data/mialab/users/AA/Zafar/adni_smri/0002/SmN...      1  76.3    29    0   \n",
       "2  /data/mialab/users/AA/Zafar/adni_smri/0003/SmN...      1  79.3    30    0   \n",
       "3  /data/mialab/users/AA/Zafar/adni_smri/0004/SmN...      3  77.5    22   25   \n",
       "4  /data/mialab/users/AA/Zafar/adni_smri/0005/SmN...      1  89.6    30    0   \n",
       "\n",
       "   CDRSB  ADAS11  ADAS13  RAVLT  \n",
       "0    0.0    3.00    4.00     56  \n",
       "1    0.0    3.33    4.33     52  \n",
       "2    0.0    6.00    8.00     48  \n",
       "3    8.0   19.33   30.33     19  \n",
       "4    0.0    3.67    6.67     36  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imported csv file containing paths to NII and labels\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"/data/mialab/users/AA/Zafar/AA_adni_smri_tbl.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ab=data.label\n",
    "dff = create_dataframe(dataset, columns=[\"class\",\"filepath\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result=pd.concat([dff,ab],axis=1)\n",
    "ddf_with_labels=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from catalyst.utils import split_dataframe_train_test\n",
    "\n",
    "train_data, valid_data = split_dataframe_train_test(\n",
    "    ddf_with_labels, test_size=0.2, random_state=SEED)\n",
    "train_data, valid_data = (\n",
    "    train_data.to_dict('records'), valid_data.to_dict('records')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ziqbal5/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/torchvision/extension.py:11: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/torchvision/_C.so'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "BORDER_CONSTANT = 0\n",
    "BORDER_REFLECT = 2\n",
    "\n",
    "def pre_transforms(image_size=224):\n",
    "    # Convert the image to a square of size image_size x image_size\n",
    "    # (keeping aspect ratio)\n",
    "    result = [\n",
    "        albu.LongestMaxSize(max_size=image_size),\n",
    "        albu.PadIfNeeded(image_size, image_size, border_mode=BORDER_CONSTANT)\n",
    "    ]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def hard_transforms():\n",
    "    result = [\n",
    "        # Random shifts, stretches and turns with a 50% probability\n",
    "        albu.ShiftScaleRotate( \n",
    "            shift_limit=0.1,\n",
    "            scale_limit=0.1,\n",
    "            rotate_limit=15,\n",
    "            border_mode=BORDER_REFLECT,\n",
    "            p=0.5\n",
    "        ),\n",
    "        albu.IAAPerspective(scale=(0.02, 0.05), p=0.3),\n",
    "        # Random brightness / contrast with a 30% probability\n",
    "        albu.RandomBrightnessContrast(\n",
    "            brightness_limit=0.2, contrast_limit=0.2, p=0.3\n",
    "        ),\n",
    "        # Random gamma changes with a 30% probability\n",
    "        albu.RandomGamma(gamma_limit=(85, 115), p=0.3),\n",
    "        # Randomly changes the hue, saturation, and color value of the input image\n",
    "        albu.HueSaturationValue(p=0.3),\n",
    "        albu.JpegCompression(quality_lower=80),\n",
    "    ]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def post_transforms():\n",
    "    # we use ImageNet image normalization\n",
    "    # and convert it to torch.Tensor\n",
    "    return [albu.Normalize(), ToTensor()]\n",
    "\n",
    "def compose(transforms_to_compose):\n",
    "    # combine all augmentations into one single pipeline\n",
    "    result = albu.Compose([\n",
    "      item for sublist in transforms_to_compose for item in sublist\n",
    "    ])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:1662: DeprecationWarning:\n",
      "\n",
      "This class has been deprecated. Please use ImageCompression\n",
      "\n",
      "/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/albumentations/pytorch/transforms.py:59: DeprecationWarning:\n",
      "\n",
      "ToTensor is deprecated and will be replaced by ToTensorV2 in albumentations 0.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catalyst.data import Augmentor\n",
    "\n",
    "\n",
    "train_transforms = compose([\n",
    "    pre_transforms(), \n",
    "    hard_transforms(), \n",
    "    post_transforms()\n",
    "])\n",
    "valid_transforms = compose([pre_transforms(), post_transforms()])\n",
    "\n",
    "show_transforms = compose([pre_transforms(), hard_transforms()])\n",
    "\n",
    "# Takes an image from the input dictionary by the key `dict_key` \n",
    "# and performs `train_transforms` on it.\n",
    "train_data_transforms = Augmentor(\n",
    "    dict_key=\"features\",\n",
    "    augment_fn=lambda x: train_transforms(image=x)[\"image\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Similarly for the validation part of the dataset. \n",
    "# we only perform squaring, normalization and ToTensor\n",
    "valid_data_transforms = Augmentor(\n",
    "    dict_key=\"features\",\n",
    "    augment_fn=lambda x: valid_transforms(image=x)[\"image\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 4\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def get_loaders(\n",
    "    open_fn: Callable,\n",
    "    train_transforms_fn,\n",
    "    valid_transforms_fn,\n",
    "    batch_size: int = 4, \n",
    "    num_workers: int = 4,\n",
    "    sampler = None\n",
    ") -> collections.OrderedDict:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        open_fn: Reader for reading data from a dataframe\n",
    "        train_transforms_fn: Augmentor for train part\n",
    "        valid_transforms_fn: Augmentor for valid part\n",
    "        batch_size: batch size\n",
    "        num_workers: How many subprocesses to use to load data,\n",
    "        sampler: An object of the torch.utils.data.Sampler class \n",
    "            for the dataset data sampling strategy specification\n",
    "    \"\"\"\n",
    "    train_loader = utils.get_loader(\n",
    "        train_data,\n",
    "        open_fn=open_fn,\n",
    "        dict_transform=train_transforms_fn,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=sampler is None, # shuffle data only if Sampler is not specified (PyTorch requirement)\n",
    "        sampler=sampler,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    valid_loader = utils.get_loader(\n",
    "        valid_data,\n",
    "        open_fn=open_fn,\n",
    "        dict_transform=valid_transforms_fn,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False, \n",
    "        sampler=None,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    # Catalyst expects an ordered dictionary with train/valid/infer loaders. \n",
    "    # The number of loaders can vary.\n",
    "    # For example, it can easily handle even some complex logic like:\n",
    "    # loaders[\"train_dataset1\"] = train_loader_1\n",
    "    # loaders[\"train_dataset2\"] = train_loader_2\n",
    "    # ....\n",
    "    # loaders[\"valid_1\"] = valid_loader_1\n",
    "    # loaders[\"valid_2\"] = valid_loader_2\n",
    "    # ...\n",
    "    # loaders[\"infer_1\"] = infer_loader_1\n",
    "    # loaders[\"infer_2\"] = infer_loader_2\n",
    "    # ...\n",
    "    \n",
    "    loaders = collections.OrderedDict()\n",
    "    loaders[\"train\"] = train_loader\n",
    "    loaders[\"valid\"] = valid_loader\n",
    "\n",
    "    return loaders\n",
    "\n",
    "if is_fp16_used:\n",
    "    batch_size = 128\n",
    "else:\n",
    "    batch_size = 4\n",
    "\n",
    "print(f\"batch_size: {batch_size}\")\n",
    "\n",
    "loaders = get_loaders(\n",
    "    open_fn=open_fn, \n",
    "    train_transforms_fn=train_data_transforms,\n",
    "    valid_transforms_fn=valid_data_transforms,\n",
    "    batch_size=batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_l4(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "    \n",
    "        self.inplanes = 64\n",
    "        super(ResNet_l4, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=3, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool3d(3)\n",
    "        self.fc = nn.Linear(4096 * block.expansion, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)        \n",
    "        x = self.layer1(x)        \n",
    "        x = self.layer2(x)        \n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_l4(\n",
      "  (conv1): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool3d(kernel_size=3, stride=3, padding=0)\n",
      "  (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=ResNet_l4(BasicBlock,[2, 2, 2, 2],4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "FP16 params: None\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[9], gamma=0.3\n",
    ")\n",
    "\n",
    "\n",
    "from catalyst.dl import SupervisedRunner\n",
    "\n",
    "num_epochs = 10\n",
    "logdir = \"./logs/classification\"\n",
    "\n",
    "device = utils.get_device()\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "if is_fp16_used:\n",
    "    fp16_params = dict(opt_level=\"O1\") # params for FP16\n",
    "else:\n",
    "    fp16_params = None\n",
    "\n",
    "print(f\"FP16 params: {fp16_params}\")\n",
    "\n",
    "runner = SupervisedRunner(device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1/10 * Epoch (train):   0% 0/165 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Caught ImportError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/plugins/simpleitk.py\", line 16, in load_lib\n    import itk as _itk\nModuleNotFoundError: No module named 'itk'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/plugins/simpleitk.py\", line 22, in load_lib\n    import SimpleITK as _itk\nModuleNotFoundError: No module named 'SimpleITK'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/catalyst/data/dataset.py\", line 50, in __getitem__\n    dict_ = self.open_fn(item)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/catalyst/data/reader.py\", line 251, in __call__\n    result = {**result, **fn(element)}\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/catalyst/data/reader.py\", line 79, in __call__\n    image_name, rootpath=self.rootpath, grayscale=self.grayscale\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/catalyst/contrib/utils/image.py\", line 73, in imread\n    img = imageio.imread(uri, as_gray=grayscale, pilmode=\"RGB\", **kwargs)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\", line 265, in imread\n    reader = read(uri, format, \"i\", **kwargs)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\", line 186, in get_reader\n    return format.get_reader(request)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/core/format.py\", line 170, in get_reader\n    return self.Reader(self, request)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/core/format.py\", line 221, in __init__\n    self._open(**self.request.kwargs.copy())\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/plugins/simpleitk.py\", line 111, in _open\n    load_lib()\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/plugins/simpleitk.py\", line 28, in load_lib\n    \"itk could not be found. \"\nImportError: itk could not be found. Please try   python -m pip install itk or   python -m pip install simpleitk or refer to   https://itkpythonpackage.readthedocs.io/ for further instructions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-e6599429e5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# prints train logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/dl/runner/core.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, scheduler, datasets, loaders, callbacks, logdir, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, state_kwargs, checkpoint_data, fp16, distributed, monitoring_params, check, timeit)\u001b[0m\n\u001b[1;32m    131\u001b[0m         )\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_cmd_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/utils/scripts.py\u001b[0m in \u001b[0;36mdistributed_cmd_run\u001b[0;34m(worker_fn, distributed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     ):\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mworker_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_rank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    508\u001b[0m             ):\n\u001b[1;32m    509\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \"\"\"\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     def _batch2device(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/callbacks/exception.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_exception_reraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    472\u001b[0m             )\n\u001b[1;32m    473\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, stage, epoch)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_loader_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_loader_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_loader\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    394\u001b[0m         )\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: Caught ImportError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/plugins/simpleitk.py\", line 16, in load_lib\n    import itk as _itk\nModuleNotFoundError: No module named 'itk'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/plugins/simpleitk.py\", line 22, in load_lib\n    import SimpleITK as _itk\nModuleNotFoundError: No module named 'SimpleITK'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/catalyst/data/dataset.py\", line 50, in __getitem__\n    dict_ = self.open_fn(item)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/catalyst/data/reader.py\", line 251, in __call__\n    result = {**result, **fn(element)}\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/catalyst/data/reader.py\", line 79, in __call__\n    image_name, rootpath=self.rootpath, grayscale=self.grayscale\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/catalyst/contrib/utils/image.py\", line 73, in imread\n    img = imageio.imread(uri, as_gray=grayscale, pilmode=\"RGB\", **kwargs)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\", line 265, in imread\n    reader = read(uri, format, \"i\", **kwargs)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\", line 186, in get_reader\n    return format.get_reader(request)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/core/format.py\", line 170, in get_reader\n    return self.Reader(self, request)\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/core/format.py\", line 221, in __init__\n    self._open(**self.request.kwargs.copy())\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/plugins/simpleitk.py\", line 111, in _open\n    load_lib()\n  File \"/home/users/ziqbal5/anaconda3/lib/python3.7/site-packages/imageio/plugins/simpleitk.py\", line 28, in load_lib\n    \"itk could not be found. \"\nImportError: itk could not be found. Please try   python -m pip install itk or   python -m pip install simpleitk or refer to   https://itkpythonpackage.readthedocs.io/ for further instructions.\n"
     ]
    }
   ],
   "source": [
    "# as we are working on classification task\n",
    "from catalyst.dl.callbacks import AccuracyCallback, AUCCallback, F1ScoreCallback\n",
    "\n",
    "callbacks = [\n",
    "    AccuracyCallback(num_classes=num_classes),\n",
    "    AUCCallback(\n",
    "        num_classes=num_classes,\n",
    "        input_key=\"targets_one_hot\"\n",
    "    ),\n",
    "    F1ScoreCallback(\n",
    "        input_key=\"targets_one_hot\",\n",
    "        activation=\"Softmax\"\n",
    "    )\n",
    "]\n",
    "\n",
    "if is_alchemy_used:\n",
    "    from catalyst.dl import AlchemyLogger\n",
    "    callbacks.append(AlchemyLogger(**monitoring_params))\n",
    "\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    # our dataloaders\n",
    "    loaders=loaders,\n",
    "    # We can specify the callbacks list for the experiment;\n",
    "    # For this task, we will check accuracy, AUC and F1 metrics\n",
    "    callbacks=callbacks,\n",
    "    # path to save logs\n",
    "    logdir=logdir,\n",
    "    num_epochs=num_epochs,\n",
    "    # save our best checkpoint by AUC metric\n",
    "    main_metric=\"auc/_mean\",\n",
    "    # AUC needs to be maximized.\n",
    "    minimize_metric=False,\n",
    "    # for FP16. It uses the variable from the very first cell\n",
    "    fp16=fp16_params,\n",
    "    # prints train logs\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
